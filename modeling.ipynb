{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "181f68e503c14848ca7b19efffda8e928d91ce23811e7019b779e3a955f1e780"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Building Recommendation System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To build this model, we'll be using `surprise`, a Python [scikit](https://www.scipy.org/scikits.html) for building and analyzing recommender systems that deal with explicit rating data\n",
    "\n",
    "You can read more about the package in the [documentation](http://surpriselib.com/) here."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from surprise.prediction_algorithms import SVD, SVDpp, knns, KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.similarities import cosine, msd, pearson\n",
    "from surprise import Dataset, accuracy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the movielens-100k datase\n",
    "\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "df = pd.read_csv('./data/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "new_df = df.drop(columns='timestamp')\n"
   ]
  },
  {
   "source": [
    "## Transforming Data\n",
    "\n",
    "It's now time to transform the dataset into something compatible with surprise. In order to do this, we're going to need Reader and Dataset classes. There's a method in Dataset specifically for loading dataframes.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(new_df,reader)"
   ]
  },
  {
   "source": [
    "Let's look at how many users and items we have in our dataset. If using neighborhood-based methods, this will help us determine whether or not we should perform user-user or item-item similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of users:  610 \n\nNumber of items:  9724\n"
     ]
    }
   ],
   "source": [
    "dataset = data.build_full_trainset()\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items)"
   ]
  },
  {
   "source": [
    "# Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Singular Value Decomposition (SVD) Model\n",
    "\n",
    "With SVD, we turn the recommendation problem into an Optimization problem that deals with how good we are in predicting the rating for items given a user. One common metric to achieve such optimization is Root Mean Square Error (RMSE). A lower RMSE is indicative of improved performance and vice versa. RMSE is minimized on the known entries in the utility matrix. SVD has a great property that it has the minimal reconstruction Sum of Square Error (SSE); therefore, it is also commonly used in dimensionality reduction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Grid Search on SVD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 4.27 s, sys: 347 ms, total: 4.62 s\nWall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'n_factors': [20, 50, 100],\n",
    "         'reg_all': [0.02, 0.05, 0.1]}\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1)\n",
    "g_s_svd.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'rmse': 0.869098218320201, 'mae': 0.6682080150046845}\n{'rmse': {'n_factors': 100, 'reg_all': 0.05}, 'mae': {'n_factors': 100, 'reg_all': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "source": [
    "Although we used gridsearch, this model had an RMSE of only 0.869. Let's see if we can improve that score.\n",
    "\n",
    "Next, let's try to cross validate with a KNN model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating with KNNBasic\n",
    "knn_basic = KNNBasic(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_basic = cross_validate(knn_basic, data, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('test_rmse', array([0.9678457 , 0.97839148, 0.96996964, 0.97358059, 0.96586955]))\n('test_mae', array([0.74840297, 0.75563622, 0.74893211, 0.75109506, 0.74412268]))\n('fit_time', (0.5178658962249756, 0.5363750457763672, 0.5197341442108154, 0.5028798580169678, 0.4622361660003662))\n('test_time', (1.6939599514007568, 1.6690781116485596, 1.6748919486999512, 1.6828718185424805, 1.6874818801879883))\n-----------------------\n0.9711313922230905\n"
     ]
    }
   ],
   "source": [
    "for i in cv_knn_basic.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_basic['test_rmse']))"
   ]
  },
  {
   "source": [
    "Let's try KNNBaseline now."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# cross validating with KNNBaseline\n",
    "knn_baseline = KNNBaseline(sim_options={'name':'pearson', 'user_based':True})\n",
    "cv_knn_baseline = cross_validate(knn_baseline,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('test_rmse', array([0.87815233, 0.87536537, 0.87740202, 0.87300185, 0.87649267]))\n('test_mae', array([0.67043078, 0.66889433, 0.66953151, 0.66893167, 0.67039132]))\n('fit_time', (0.756706953048706, 0.769845724105835, 0.7901058197021484, 0.8651351928710938, 0.6298890113830566))\n('test_time', (1.6798529624938965, 1.7510740756988525, 1.6572132110595703, 2.2883729934692383, 1.7342009544372559))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8760828469416297"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "for i in cv_knn_baseline.items():\n",
    "    print(i)\n",
    "\n",
    "np.mean(cv_knn_baseline['test_rmse'])"
   ]
  },
  {
   "source": [
    "Based off these outputs, it seems like the best performing model is the SVD model with n_factors = 50 and a regularization rate of 0.05. Use that model or if you found one that performs better, feel free to use that to make some predictions.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Making Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('./data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "source": [
    "## Simple Predictions\n",
    "\n",
    "First, we'll fit the SVD model we had from before. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors= 50, reg_all=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3.18 s, sys: 38.6 ms, total: 3.22 s\nWall time: 3.26 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fb725478460>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=4, r_ui=None, est=3.1097730823247884, details={'was_impossible': False})"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "svd.predict(2, 4)"
   ]
  },
  {
   "source": [
    "This prediction value is a tuple and each of the values within it can be accessed by way of indexing. \n",
    "\n",
    "Next, we can make predictions for a new user."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Obtaining User Ratings\n",
    "\n",
    "The first step is to create a function that allows us to pick randomly selected movies. The function should present users with a movie and ask them to rate it. If they have not seen the movie, they should be able to skip rating it.\n",
    "\n",
    "The function `movie_rater()` takes the parameters:\n",
    "\n",
    "- `movie_df`: DataFrame - a dataframe containing the movie ids, name of movie, and genres\n",
    "- `num`: int - number of ratings\n",
    "- `genre`: string - a specific genre from which to draw movies\n",
    "\n",
    "The function returns:\n",
    "- `rating_list`: list - a collection of dictionaries in the format of {'userId': int , 'movieId': int , 'rating': float}\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rater(movie_df,num, genre=None):\n",
    "    userID = 1000\n",
    "    rating_list = []\n",
    "    while num > 0:\n",
    "        if genre:\n",
    "            movie = movie_df[movie_df['genres'].str.contains(genre)].sample(1)\n",
    "        else:\n",
    "            movie = movie_df.sample(1)\n",
    "        print(movie)\n",
    "        rating = input('How do you rate this movie on a scale of 1-5, press n if you have not seen :\\n')\n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            rating_one_movie = {'userId':userID,'movieId':movie['movieId'].values[0],'rating':rating}\n",
    "            rating_list.append(rating_one_movie) \n",
    "            num -= 1\n",
    "    return rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      movieId                    title  genres\n",
      "1680     2261  One Crazy Summer (1986)  Comedy\n",
      "      movieId                                title                      genres\n",
      "7929    95543  Ice Age 4: Continental Drift (2012)  Adventure|Animation|Comedy\n",
      "      movieId                      title          genres\n",
      "3698     5102  Rookie of the Year (1993)  Comedy|Fantasy\n",
      "      movieId                         title            genres\n",
      "3673     5060  M*A*S*H (a.k.a. MASH) (1970)  Comedy|Drama|War\n"
     ]
    }
   ],
   "source": [
    "user_rating = movie_rater(df_movies, 4, 'Comedy')"
   ]
  },
  {
   "source": [
    "## Making Predictions with the New Ratings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the new ratings to the original ratings DataFrame\n",
    "new_ratings_df = new_df.append(user_rating,ignore_index=True)\n",
    "new_data = Dataset.load_from_df(new_ratings_df,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3.26 s, sys: 46.1 ms, total: 3.3 s\nWall time: 3.34 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fb7396f5e20>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "%%time\n",
    "# train a model using the new combined DataFrame\n",
    "svd_ = SVD(n_factors= 50, reg_all=0.05)\n",
    "svd_.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the user\n",
    "# creating a list of tuples in the format (movie_id, predicted_score)\n",
    "list_of_movies = []\n",
    "for m_id in new_df['movieId'].unique():\n",
    "    list_of_movies.append( (m_id,svd_.predict(1000,m_id)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the predictions from highest to lowest rated\n",
    "ranked_movies = sorted(list_of_movies, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "source": [
    "Creating a function `recommended_movies()` that takes in the parameters:\n",
    "\n",
    "- `user_ratings`: list - list of tuples formulated as (user_id, movie_id) (should be in order of best to worst for this individual)\n",
    "- `movie_title_df`: DataFrame\n",
    "- `n`: int - number of recommended movies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recommendation #  1 :  4909    Eternal Sunshine of the Spotless Mind (2004)\nName: title, dtype: object \n\nRecommendation #  2 :  602    Dr. Strangelove or: How I Learned to Stop Worr...\nName: title, dtype: object \n\nRecommendation #  3 :  277    Shawshank Redemption, The (1994)\nName: title, dtype: object \n\nRecommendation #  4 :  906    Lawrence of Arabia (1962)\nName: title, dtype: object \n\nRecommendation #  5 :  901    Brazil (1985)\nName: title, dtype: object \n\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations\n",
    "def recommended_movies(user_ratings,movie_title_df,n):\n",
    "        for idx, rec in enumerate(user_ratings):\n",
    "            title = movie_title_df.loc[movie_title_df['movieId'] == int(rec[0])]['title']\n",
    "            print('Recommendation # ', idx+1, ': ', title, '\\n')\n",
    "            n-= 1\n",
    "            if n == 0:\n",
    "                break\n",
    "            \n",
    "recommended_movies(ranked_movies,df_movies,5)"
   ]
  }
 ]
}